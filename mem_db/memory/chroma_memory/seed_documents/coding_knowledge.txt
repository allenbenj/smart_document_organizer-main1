# legal_agent_pipeline.py

import os
import subprocess
from pathlib import Path
from langchain_openai import ChatOpenAI

# Define folder structure
folders = [
    "raw_documents",
    "parsed_text",
    "facts_extracted",
    "legal_issues",
    "case_timeline",
    "legal_arguments",
    "executive_summary",
    "logs"
]

# Ensure folders exist
def setup_directories():
    for folder in folders:
        Path(folder).mkdir(exist_ok=True)
    print("‚úÖ Directory structure initialized.")

# Robust LangChain/OpenAI client with error handling
def robust_llm_call(prompt, model_name="mistral", base_url="http://localhost:1234/v1", retries=5, timeout=120):
    llm = ChatOpenAI(
        model_name=model_name,
        base_url=base_url,
        max_retries=retries,
        timeout=timeout,
        streaming=False  # Temporarily disable streaming to improve reliability
    )
    try:
        response = llm.invoke(prompt)
        return response.content
    except Exception as e:
        print(f"‚ö†Ô∏è Error invoking model: {e}")
        return None

# Mock agent execution (replace this with actual agent call logic)
def run_agent(agent_name, input_path, output_path, prompt_path):
    print(f"üîç Running {agent_name}...")
    prompt = f"Process input from {input_path} using prompt {prompt_path}"
    response = robust_llm_call(prompt)
    if response:
        output_file = os.path.join(output_path, f"{agent_name}_output.txt")
        with open(output_file, "w") as f:
            f.write(response)
        print(f"‚úÖ {agent_name} completed. Output saved to {output_file}")
    else:
        print(f"‚ùå {agent_name} failed.")

# Define agents and their configuration
agents = [
    {"name": "document_parser", "input": "raw_documents", "output": "parsed_text", "prompt": "prompts/reflection/agent.system.main.parser.md"},
    {"name": "fact_extractor", "input": "parsed_text", "output": "facts_extracted", "prompt": "prompts/reflection/agent.system.main.factextractor.md"},
    {"name": "issue_mapper", "input": "facts_extracted", "output": "legal_issues", "prompt": "prompts/reflection/agent.system.main.issuemapper.md"},
    {"name": "timeline_builder", "input": "facts_extracted", "output": "case_timeline", "prompt": "prompts/reflection/agent.system.main.timelinebuilder.md"},
    {"name": "argument_mapper", "input": "facts_extracted", "output": "legal_arguments", "prompt": "prompts/reflection/agent.system.main.argumentmapper.md"},
    {"name": "summarizer", "input": "legal_arguments", "output": "executive_summary", "prompt": "prompts/reflection/agent.system.main.summarizer.md"}
]

# Execute pipeline
def run_pipeline():
    setup_directories()
    for agent in agents:
        run_agent(
            agent_name=agent["name"],
            input_path=agent["input"],
            output_path=agent["output"],
            prompt_path=agent["prompt"]
        )

if __name__ == "__main__":
    run_pipeline()

You can also use external sources if needed